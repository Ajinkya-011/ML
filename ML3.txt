10/26/23, 6:19 PM

ML3.ipynb - Colaboratory

import pandas as pd
import numpy as np
import seaborn as sns
df=pd.read_csv("/content/Admission_Predict.csv")
df=pd.read_csv("/content/Admission_Predict_Ver1.1.csv")
df.columns
Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',
'LOR ', 'CGPA', 'Research', 'Chance of Admit '],
dtype='object')

Default title text
# @title Default title text
df.shape
(500, 9)
from sklearn.preprocessing import Binarizer
bi=Binarizer(threshold=0.75)
df['Chance of Admit ']=bi.fit_transform(df[['Chance of Admit ']])
df.head()
Serial No.

GRE Score

TOEFL Score

University Rating

SOP

LOR

CGPA

Research Chance of Admit

0

1

337

118

4

4.5

4.5

9.65

1

1.0

1

2

324

107

4

4.0

4.5

8.87

1

1.0

2

3

316

104

3

3.0

3.5

8.00

1

0.0

3

4

322

110

3

3.5

2.5

8.67

1

1.0

4

5

314

103

2

2.0

3.0

8.21

0

0.0

x=df.drop('Chance of Admit ',axis=1)
y=df['Chance of Admit ']
x
Serial
No.

GRE
Score

TOEFL
Score

University
Rating

SOP

LOR

CGPA

Research

0

1

337

118

4

4.5

4.5

9.65

1

1

2

324

107

4

4.0

4.5

8.87

1

2

3

316

104

3

3.0

3.5

8.00

1

3

4

322

110

3

3.5

2.5

8.67

1

4

5

314

103

2

2.0

3.0

8.21

0

...

...

...

...

...

...

...

...

...

495

496

332

108

5

4.5

4.0

9.02

1

496

497

337

117

5

5.0

5.0

9.87

1

497

498

330

120

5

4.5

5.0

9.56

1

498

499

312

103

4

4.0

5.0

8.43

0

499

500

327

113

4

4.5

4.5

9.04

0

500 rows × 8 columns

y=y.astype('int')
y

0
1
2
3

1
1
0
1

https://colab.research.google.com/drive/1oOLiQlFrMsw2KRfULYFT4HG16lYt1SQs#printMode=true

1/4

10/26/23, 6:19 PM

ML3.ipynb - Colaboratory

4

0
..
495
1
496
1
497
1
498
0
499
1
Name: Chance of Admit , Length: 500, dtype: int64
sns.countplot(x = y)
<Axes: xlabel='Chance of Admit ', ylabel='count'>

y.value_counts()
0
290
1
210
Name: Chance of Admit , dtype: int64
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.25)
xt=x_train.shape
print("The shape of traning data is:",xt)
The shape of traning data is: (375, 8)
xxt=x_test.shape
print("The shape of testing data is:",xxt)
The shape of traning data is: (125, 8)
yt=y_train.shape
print("The shape of traning data is:",yt)
The shape of traning data is: (375,)
yyt=y_test.shape
print("The shape of testing data is:",yyt)

The shape of traning data is: (125,)
from sklearn.tree import DecisionTreeClassifier

classifier=DecisionTreeClassifier(random_state=0)
classifier.fit(x_train,y_train)

https://colab.research.google.com/drive/1oOLiQlFrMsw2KRfULYFT4HG16lYt1SQs#printMode=true

2/4

10/26/23, 6:19 PM

ML3.ipynb - Colaboratory

▾
DecisionTreeClassifier
y_pred=classifier.predict(x_test) #prediction based on input means x
DecisionTreeClassifier(random_state=0)
#comparing acutal and predict
result=pd.DataFrame({
'actual':y_test, #already known values
'predicted':y_pred #predictedvalues
})
result
actual

predicted

90

0

0

254

1

1

283

1

1

445

1

1

461

0

0

...

...

...

430

0

0

49

1

0

134

1

1

365

1

1

413

0

0

125 rows × 2 columns

from sklearn.metrics import ConfusionMatrixDisplay,accuracy_score
from sklearn.metrics import classification_report
ConfusionMatrixDisplay.from_predictions (y_test,y_pred)
<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7990a6004130>

accuracy=accuracy_score(y_test,y_pred)
print("The accuracy is:",accuracy)
The accuracy is: 0.96
print(classification_report(y_test,y_pred))
precision

recall

f1-score

support

0
1

0.96
0.95

0.98
0.93

0.97
0.94

81
44

accuracy
macro avg
weighted avg

0.96
0.96

0.95
0.96

0.96
0.96
0.96

125
125
125

https://colab.research.google.com/drive/1oOLiQlFrMsw2KRfULYFT4HG16lYt1SQs#printMode=true

3/4

10/26/23, 6:19 PM

ML3.ipynb - Colaboratory

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
plt.figure(figsize=(15,15))
plot_tree(classifier, fontsize=6,filled=True );

https://colab.research.google.com/drive/1oOLiQlFrMsw2KRfULYFT4HG16lYt1SQs#printMode=true

4/4

